---
title: "SpecLig: Energy-Guided Hierarchical Model for Target-Specific 3D Ligand Design"
date: 2026-02-19 10:00:00 +0900
description: "SpecLig tackles off-target binding in structure-based drug design by integrating hierarchical SE(3)-equivariant VAE with energy-guided latent diffusion using block-block contact statistics, achieving high affinity and specificity for both small molecules and peptides."
categories: [AI, Drug Discovery]
tags: [protein-ligand, drug-design, diffusion, equivariant, specificity, SBDD, VAE, energy-guidance]
math: true
mermaid: true
image:
  path: https://www.biorxiv.org/content/biorxiv/early/2025/11/08/2025.11.06.687093/F1.large.jpg
  alt: "SpecLig framework overview showing energy-guided hierarchical architecture"
---

## Hook

ì•½ì„ ì„¤ê³„í•˜ëŠ” AIê°€ ìˆë‹¤. Binding affinityëŠ” ë†’ê²Œ ì¡ëŠ”ë°, ë¬¸ì œëŠ” íƒ€ê²Ÿì´ ì•„ë‹Œ ë‹¨ë°±ì§ˆì—ë„ ë§ˆêµ¬ ë¶™ëŠ”ë‹¤ëŠ” ê²ƒì´ë‹¤. ê¸°ì¡´ structure-based drug design (SBDD) ëª¨ë¸ë“¤ì€ ë‹¨ì¼ íƒ€ê²Ÿì— ëŒ€í•œ ê²°í•©ë ¥ ìµœì í™”ì—ë§Œ ì§‘ì¤‘í•˜ë‹¤ ë³´ë‹ˆ, ìƒì„±ëœ ë¶„ìë“¤ì´ off-targetì—ë„ ê°•í•˜ê²Œ ê²°í•©í•˜ëŠ” promiscuous binderê°€ ë˜ì–´ë²„ë¦°ë‹¤. SpecLigëŠ” "ìì—°ì´ ì´ë¯¸ ì•Œê³  ìˆëŠ” ë¶„ì ê¶í•© ì •ë³´"ë¥¼ diffusion ê³¼ì •ì— ì£¼ì…í•´ì„œ, íŠ¹ì • íƒ€ê²Ÿì—ë§Œ ì„ íƒì ìœ¼ë¡œ ê²°í•©í•˜ëŠ” ë¶„ìë¥¼ ë§Œë“ ë‹¤.

## Problem

SBDD ëª¨ë¸ë“¤ì€ receptorì˜ 3D êµ¬ì¡°ë¥¼ í™œìš©í•´ í™”í•™ì Â·ê³µê°„ì ìœ¼ë¡œ í•©ë¦¬ì ì¸ ë¦¬ê°„ë“œë¥¼ ìƒì„±í•œë‹¤. í•˜ì§€ë§Œ ëŒ€ë¶€ë¶„ì˜ ëª¨ë¸ì€ ë‹¨ì¼ íƒ€ê²Ÿ êµ¬ì¡°ì—ë§Œ ì¡°ê±´ì„ ê±¸ì–´ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì—, training dataì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” motifë¥¼ ë°˜ë³µì ìœ¼ë¡œ ìƒì„±í•œë‹¤. ì´ëŸ° motifëŠ” predicted affinityë¥¼ ë†’ì¼ ìˆ˜ëŠ” ìˆì§€ë§Œ, íƒ€ê²Ÿ íŠ¹ì´ì„±(specificity)ì„ ë–¨ì–´ëœ¨ë¦°ë‹¤.

![Figure 1: Off-target analysis](https://www.biorxiv.org/content/biorxiv/early/2025/11/08/2025.11.06.687093/F1.large.jpg)
_Figure 1: ê¸°ì¡´ SBDD ëª¨ë¸ì˜ off-target binding ë¬¸ì œì™€ SpecLigì˜ hierarchical architecture. (a-b) VoxBindì™€ PepGLADê°€ ìƒì„±í•œ ë¦¬ê°„ë“œê°€ target (ë¶„í™)ë³´ë‹¤ non-target (íŒŒë‘)ì— ë” ê°•í•˜ê²Œ ê²°í•©. (c-d) Low-specificity ë””ìì¸ì˜ í™”í•™ì  íŠ¹ì§•. (e-f) SpecLigì˜ block-block frequency matrix êµ¬ì¶•ê³¼ energy-guided diffusion. ì¶œì²˜: ì› ë…¼ë¬¸_

ë…¼ë¬¸ì€ VoxBindì™€ PepGLAD ê°™ì€ ëª¨ë¸ì´ native ligandë³´ë‹¤ ë†’ì€ predicted affinityë¥¼ ë³´ì˜€ì§€ë§Œ, ë™ì‹œì— unrelated proteinì—ë„ ê°•í•˜ê²Œ ê²°í•©í•˜ëŠ” ì‚¬ë¡€ë¥¼ ë³´ì—¬ì¤€ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ cytochrome P450BM-3ë¥¼ íƒ€ê²Ÿìœ¼ë¡œ ìƒì„±ëœ small moleculeì´ aldehyde decarbonylaseë¼ëŠ” ë¬´ê´€í•œ ë‹¨ë°±ì§ˆì— ë” ë†’ì€ docking scoreë¥¼ ê¸°ë¡í–ˆë‹¤. Interaction ë¶„ì„ ê²°ê³¼, ìƒì„±ëœ ë¦¬ê°„ë“œì˜ ì¼ë¶€ fragmentê°€ intended targetê³¼ëŠ” ë³„ë¡œ ìƒí˜¸ì‘ìš©í•˜ì§€ ì•Šìœ¼ë©´ì„œ off-targetê³¼ëŠ” ì£¼ìš” ê²°í•©ì„ í˜•ì„±í–ˆë‹¤.

ì €ìë“¤ì€ ì—¬ëŸ¬ SBDD ëª¨ë¸ì˜ ì¶œë ¥ì„ specificity ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¥˜í–ˆë‹¤. ë‚®ì€ specificityë¥¼ ê°€ì§„ small moleculeì€ polar group ë¹„ìœ¨ì´ ì•½ 5-10% ë” ë†’ì•˜ê³ , ì´ëŠ” ì—¬ëŸ¬ íƒ€ê²Ÿì— promiscuousí•˜ê²Œ ê²°í•©í•˜ëŠ” ê²½í–¥ì„ ë³´ì˜€ë‹¤. Peptideì˜ ê²½ìš° high-specificity designì€ helical structure ë¹„ìœ¨ì´ 3-10% ë” ë†’ì•˜ê³ , non-helical flexible segmentëŠ” ë…¸ì¶œ ìœ„í—˜ì„ ì¦ê°€ì‹œì¼°ë‹¤.

ê¸°ì¡´ SBDD ë²¤ì¹˜ë§ˆí¬ëŠ” single-target docking scoreì—ë§Œ ì§‘ì¤‘í•˜ë©°, ê³¼ë„í•œ modificationì„ í†µí•´ ë†’ì€ scoreë¥¼ ì–»ì„ ìˆ˜ ìˆì§€ë§Œ promiscuityë¥¼ ê°ì¶”ëŠ” ë¬¸ì œê°€ ìˆë‹¤. Specificityë¥¼ ì •ëŸ‰í™”í•˜ëŠ” ê¸°ì¡´ ì‹œë„ë“¤ì€ random non-targetê³¼ ë¹„êµí•˜ëŠ” ìˆ˜ì¤€ì— ê·¸ì³ actionable guidanceë¥¼ ì œê³µí•˜ì§€ ëª»í–ˆë‹¤.

## Key Idea

SpecLigì˜ í•µì‹¬ ì•„ì´ë””ì–´ëŠ” **evolutionary binding preferenceë¥¼ statistical energyë¡œ í™œìš©**í•˜ëŠ” ê²ƒì´ë‹¤. ë‹¨ì¼ êµ¬ì¡°ì—ë§Œ conditioningí•˜ëŠ” ëŒ€ì‹ , native protein-ligand complexì—ì„œ ì¶”ì¶œí•œ block-block contact frequencyë¥¼ empirical potentialë¡œ ë³€í™˜í•œë‹¤.

Blockì€ amino acid residue ë˜ëŠ” predefined molecular fragmentë¥¼ ì˜ë¯¸í•œë‹¤. SpecLigëŠ” ìˆ˜ë°±ë§Œ ê°œì˜ natural complexì—ì„œ "ì–´ë–¤ fragmentê°€ ì–´ë–¤ fragmentì™€ ìì£¼ í•¨ê»˜ ë“±ì¥í•˜ëŠ”ê°€"ë¥¼ í†µê³„ì ìœ¼ë¡œ ì§‘ê³„í•œë‹¤. ì´ frequency matrixë¥¼ statistical potentialë¡œ ë³€í™˜í•˜ì—¬, diffusion sampling ê³¼ì •ì—ì„œ energy guidanceë¡œ ì‚¬ìš©í•œë‹¤.

ê¸°ì¡´ì˜ ë¬¼ë¦¬ ê¸°ë°˜ energy functionê³¼ ë‹¬ë¦¬, ì´ statistical potentialì€ "íŠ¹ì • inter-fragment interactionì´ ë‹¤ì–‘í•œ íƒ€ê²Ÿì—ì„œ ì–¼ë§ˆë‚˜ ì„ í˜¸ë˜ëŠ”ì§€"ë¥¼ ì •ëŸ‰í™”í•œë‹¤. ë”°ë¼ì„œ ëª¨ë¸ì€ ì¼ë°˜ì ì¸ promiscuous motif ëŒ€ì‹ , í˜„ì¬ query pocketê³¼ ìœ ì‚¬í•œ í™˜ê²½ì—ì„œ ì—­ì‚¬ì ìœ¼ë¡œ ë“±ì¥í–ˆë˜ fragment combinationì„ ì„ í˜¸í•˜ê²Œ ëœë‹¤.

ì´ë¥¼ êµ¬í˜„í•˜ê¸° ìœ„í•´ SpecLigëŠ” hierarchical SE(3)-equivariant VAEì™€ energy-guided latent diffusion modelì„ ê²°í•©í•œë‹¤. Atom-level encoderëŠ” local chemistryì™€ bond orderë¥¼ í¬ì°©í•˜ê³ , block-level encoderëŠ” global topologyë¥¼ reduced costë¡œ í‘œí˜„í•œë‹¤. Latent diffusion ê³¼ì •ì—ì„œ chemical priorë¥¼ additive guidanceë¡œ ì£¼ì…í•˜ì—¬, pocket-complementary fragment combinationì„ ìš°ì„ ì ìœ¼ë¡œ ìƒì„±í•œë‹¤.

## How it works

### Overview

SpecLigëŠ” í¬ê²Œ ì„¸ ê°€ì§€ êµ¬ì„±ìš”ì†Œë¡œ ë‚˜ë‰œë‹¤: (1) Hierarchical SE(3)-equivariant VAE encoder, (2) Energy-guided latent diffusion model, (3) Hierarchical decoder.

```mermaid
graph TD
    A[Protein-Ligand Complex<br/>Block Graph G] --> B[Atom-level Encoder â„°Î¾,1]
    B --> C[Block-level Encoder â„°Î¾,2]
    C --> D[Latent Representation Z]
    
    D --> E[Energy-Guided<br/>Latent Diffusion]
    
    F[Block-Block Frequency Matrix F] --> G[Statistical Energy E]
    G --> E
    
    E --> H[Denoised Latent Zâ‚€]
    
    H --> I[Block-level Decoder ğ’ŸÏ•,2]
    I --> J[Atom-level Decoder ğ’ŸÏ•,1]
    
    J --> K[Generated Ligand<br/>Block Types + 3D Coords]
    
    style A fill:#e1f5fe
    style K fill:#e8f5e9
    style E fill:#fff3e0
    style G fill:#fce4ec
```

ì „ì²´ generation ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ëœë‹¤:

$$p(G_L | G_P) = \int p_\theta(G_L | Z_0, Z_P) \cdot p_\theta(Z_0 | Z_T, Z_P) \cdot p(Z_T) \, dZ_0 dZ_T$$

ì—¬ê¸°ì„œ $G_P$ëŠ” pocket, $G_L$ì€ ligand, $Z_P$ëŠ” pocketì˜ latent representation, $Z_0$ëŠ” noise-free ligand latent, $Z_T$ëŠ” terminal Gaussian noiseë‹¤.

```python
# Overall Architecture Pseudocode
class SpecLig(nn.Module):
    def __init__(self, vocab_size, latent_dim=8):
        super().__init__()
        # Hierarchical VAE: atom and block encoders/decoders
        self.atom_enc = AtomLevelEncoder()      # â„°Î¾,1
        self.block_enc = BlockLevelEncoder()    # â„°Î¾,2
        self.block_dec = BlockLevelDecoder()    # ğ’ŸÏ•,2
        self.atom_dec = AtomLevelDecoder()      # ğ’ŸÏ•,1
        
        # Latent diffusion model
        self.diff_model = LatentDiffusion(latent_dim)
        
        # Statistical energy prior (frequency matrix F)
        self.register_buffer('freq_mat', 
                           self.build_frequency_matrix())  # F: (vocab_size, vocab_size)
    
    def encode(self, complex_graph):
        # Step 1: Atom-scale encoding
        atom_feats = self.atom_enc(complex_graph)
        
        # Step 2: Block-scale encoding with reparameterization
        mu, logvar = self.block_enc(atom_feats)
        z = self.reparameterize(mu, logvar)  # (num_blocks, latent_dim)
        
        return z, mu, logvar
    
    def decode(self, z):
        # Step 1: Block-level decoding â†’ block types + centroids
        block_types, centroids = self.block_dec(z)
        
        # Step 2: Atom-level decoding â†’ full 3D coordinates
        atoms = self.atom_dec(block_types, centroids, z)
        
        return atoms
    
    def forward(self, pocket, ligand=None):
        # Encoding (training mode with ground-truth ligand)
        z_P = self.encode(pocket)[0]
        z_L, mu, logvar = self.encode(ligand)
        
        # Latent diffusion with energy guidance
        z_0 = self.diff_model.sample(z_L, z_P, self.freq_mat)
        
        # Decoding
        gen_ligand = self.decode(z_0)
        
        return gen_ligand, mu, logvar
```

### Representation

SpecLigëŠ” protein-ligand complexë¥¼ **block-based graph** $G = (V, E)$ë¡œ í‘œí˜„í•œë‹¤. ê° node $v_i \in V$ëŠ” í•˜ë‚˜ì˜ blockì„ ë‚˜íƒ€ë‚´ë©°, unordered set of atoms $\\{(a_j, \mathbf{x}_j)\\}_{j=1}^{n_i}$ë¡œ êµ¬ì„±ëœë‹¤. ì—¬ê¸°ì„œ $a_j$ëŠ” element type, $\mathbf{x}_j$ëŠ” 3D coordinateë‹¤.

Block vocabulary $S$ëŠ” canonical amino acid residueì™€ predefined small-molecule fragmentë¡œ êµ¬ì„±ëœë‹¤. Small-molecule fragmentëŠ” ZINC15ì™€ ChEMBL databaseì—ì„œ ìˆ˜ë°±ë§Œ ê°œì˜ ë¶„ìë¥¼ principal-subgraph algorithmìœ¼ë¡œ ë¶„í•´í•˜ì—¬ ì–»ëŠ”ë‹¤. ê° blockì—ëŠ” type $s_i \in S$ê°€ í• ë‹¹ë˜ê³ , canonical residueë¡œ ì œí•œí• ì§€ ì—¬ë¶€ë¥¼ ë‚˜íƒ€ë‚´ëŠ” flag $p_i \in \\{0, 1\\}$ì´ ë¶€ì—¬ëœë‹¤.

Edge $E$ëŠ” intra-block bond, inter-block bond, spatial adjacencyë¥¼ ê¸°ë¡í•œë‹¤. Pocketì€ native ligandì˜ ì–´ë–¤ atomìœ¼ë¡œë¶€í„° 10Ã… ì´ë‚´ì— reference point (CÎ² ë˜ëŠ” fragment centroid)ê°€ ìœ„ì¹˜í•œ blockë“¤ë¡œ ì •ì˜ëœë‹¤.

ì´ëŸ¬í•œ hierarchical representationì˜ ì¥ì ì€ (1) atom-level noiseë¥¼ filteringí•˜ë©´ì„œ fragment semanticì„ ë³´ì¡´í•˜ê³ , (2) global topologyë¥¼ reduced computational costë¡œ ëª¨ë¸ë§í•˜ë©°, (3) statistical priorë¥¼ block ë‹¨ìœ„ë¡œ íš¨ìœ¨ì ìœ¼ë¡œ ì ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì´ë‹¤.

### Hierarchical VAE Architecture

Atom-level encoder $\mathcal{E}_{\xi,1}$ì€ SE(3)-equivariant transformerë¡œ êµ¬í˜„ëœë‹¤. ê° atomì€ ë‹¤ìŒ featureë¡œ ì¸ì½”ë”©ëœë‹¤: element type, parent block type, canonical-residue flag, chain ID. ì¤‘ìš”í•œ ì ì€ atom featureì— **frequency matrixì—ì„œ í•™ìŠµëœ correlated projection**ì„ augmentationí•œë‹¤ëŠ” ê²ƒì´ë‹¤.

```python
# Atom-level Encoder with Frequency Matrix Augmentation
class AtomLevelEncoder(nn.Module):
    def __init__(self, vocab_size, hidden_dim=128, num_layers=6):
        super().__init__()
        self.atom_embed = nn.Embedding(100, hidden_dim)  # 100 element types
        self.block_embed = nn.Embedding(vocab_size, hidden_dim)
        
        # Frequency matrix projection (augmentation)
        self.freq_proj = nn.Linear(vocab_size, hidden_dim)
        self.temperature = 1.0
        
        # SE(3)-equivariant transformer layers
        self.layers = nn.ModuleList([
            SE3TransformerLayer(hidden_dim) 
            for _ in range(num_layers)
        ])
    
    def forward(self, atoms, blocks, freq_matrix):
        # atoms: (N_atoms, 3)  positions
        # blocks: (N_atoms,)   parent block id
        # freq_matrix: (vocab_size, vocab_size)
        
        # Initial embedding
        h_atom = self.atom_embed(atoms.element_type)
        h_block = self.block_embed(blocks.type)
        
        # Augment with frequency matrix correlation
        # Temperature-scaled normalization
        F_norm = torch.softmax(freq_matrix / self.temperature, dim=-1)
        freq_feature = self.freq_proj(F_norm[blocks.type])
        
        h = h_atom + h_block + freq_feature  # (N_atoms, hidden_dim)
        
        # Build KNN graph (restricted within GL or GP separately)
        edge_index = self.build_knn_graph(atoms.pos, k=10, 
                                          separate_chains=True)
        
        # Edge features: {same_block, distance, bond_type}
        edge_attr = self.compute_edge_features(edge_index, atoms, blocks)
        
        # SE(3)-equivariant message passing
        for layer in self.layers:
            h, atoms.pos = layer(h, atoms.pos, edge_index, edge_attr)
        
        return h  # (N_atoms, hidden_dim)
```

Information flowëŠ” GLê³¼ GPë¥¼ ë”°ë¡œ ì²˜ë¦¬í•˜ì—¬ information leakageë¥¼ ë°©ì§€í•œë‹¤. Block-level encoder $\mathcal{E}_{\xi,2}$ëŠ” atom-level featureë¥¼ aggregationí•˜ì—¬ block-level latent representationì„ ìƒì„±í•œë‹¤. ê° blockë§ˆë‹¤ 8ì°¨ì› latent vector $z_i = (\mathbf{z}_i^{attr}, \mathbf{z}_i^{coord}) \in \mathbb{R}^8$ê°€ ìƒì„±ë˜ë©°, ì¼ë¶€ëŠ” block type/attributeë¥¼, ë‚˜ë¨¸ì§€ëŠ” coordinate informationì„ ì¸ì½”ë”©í•œë‹¤.

DecoderëŠ” encoderì˜ ì—­ìˆœìœ¼ë¡œ ë™ì‘í•œë‹¤. Block-level decoder $\mathcal{D}_{\phi,2}$ëŠ” latent $Z$ë¥¼ ë°›ì•„ block type probabilityì™€ coarse centroidë¥¼ ì˜ˆì¸¡í•œë‹¤. Atom-level decoder $\mathcal{D}_{\phi,1}$ì€ ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ full-atom 3D coordinateì™€ bond typeì„ ì¬êµ¬ì„±í•œë‹¤.

### Statistical Energy Guidance

SpecLigì˜ í•µì‹¬ í˜ì‹ ì€ **statistical energy guidance**ë¥¼ latent diffusionì— í†µí•©í•œ ê²ƒì´ë‹¤.

Frequency matrix $F \in \mathbb{R}^{n_s \times n_s}$ëŠ” ì„¸ ê°€ì§€ sourceì—ì„œ ìˆ˜ì§‘ëœë‹¤:

1. **Fragment-fragment co-occurrence**: ZINC15, ChEMBLì—ì„œ ìˆ˜ë°±ë§Œ small moleculeì„ principal-subgraph algorithmìœ¼ë¡œ ë¶„í•´í•˜ì—¬ fragment pair ë¹ˆë„ ì§‘ê³„
2. **Residue pair bonding**: RCSB PDB, PepBDBì—ì„œ inter-chain hydrogen bondë¥¼ trajectory-based analysisë¡œ ì¶”ì¶œ
3. **Protein-ligand interaction**: PDBbind, Binding-MOADì—ì„œ BINANAë¥¼ ì‚¬ìš©í•œ interaction frequency

ê° sourceë³„ë¡œ frequency matrixë¥¼ êµ¬ì¶•í•œ í›„, modal biasë¥¼ ì¤„ì´ê¸° ìœ„í•´ normalizeí•˜ê³ , log-transformí•˜ì—¬ continuous statistical potentialë¡œ ë³€í™˜í•œë‹¤:

$$F_{ij} = \log\left(\frac{\text{count}(s_i, s_j)}{\sum_{k} \text{count}(s_i, s_k)} + \epsilon\right)$$

Latent diffusionì˜ ê° reverse stepì—ì„œ, í˜„ì¬ denoised estimateë¡œë¶€í„° block type probability $\hat{s}$ë¥¼ frozen decoderë¡œ ì˜ˆì¸¡í•œë‹¤. Block pair $(i, j)$ì— ëŒ€í•œ pairwise energyëŠ”:

$$E_{ij}(\hat{s}_i, \hat{s}_j) = -\omega_{ij} \sum_{s_i, s_j} \hat{s}_i(s_i) \cdot F_{s_i, s_j} \cdot \hat{s}_j(s_j) / \tau$$

ì—¬ê¸°ì„œ $\tau$ëŠ” temperature smoothing factor, $\omega_{ij}$ëŠ” distance-dependent decayë‹¤. Total energy $E$ëŠ” ëª¨ë“  block pairì— ëŒ€í•´ í•©ì‚°í•˜ê³ , molecular massë¡œ normalizeí•œë‹¤.

```python
# Energy-Guided Sampling
class EnergyGuidedDiffusion(nn.Module):
    def __init__(self, freq_matrix, temperature=1.0):
        super().__init__()
        self.freq_matrix = freq_matrix  # F: (vocab_size, vocab_size)
        self.temperature = temperature
    
    def compute_energy(self, z_t, block_decoder):
        """
        Compute statistical energy from current latent state
        z_t: (batch, num_blocks, latent_dim)
        Returns: E (scalar)
        """
        # Decode block type probabilities (frozen decoder)
        with torch.no_grad():
            block_probs = block_decoder.predict_type_probs(z_t)
            # block_probs: (batch, num_blocks, vocab_size)
        
        # Threshold probabilities for stability
        block_probs = torch.clamp(block_probs, min=1e-6)
        
        # Compute pairwise energy for all block pairs
        B, N, V = block_probs.shape
        energy = 0.0
        
        for i in range(N):
            for j in range(i+1, N):
                # Distance-dependent decay
                dist = torch.norm(z_t[:, i, :3] - z_t[:, j, :3], dim=-1)
                omega_ij = torch.exp(-dist / 5.0)  # decay scale = 5Ã…
                
                # Pairwise energy: -Ï‰_ij * Î£ p_i(s_i) * F[s_i,s_j] * p_j(s_j)
                pairwise = torch.einsum('bi,ij,bj->b', 
                                       block_probs[:, i],
                                       self.freq_matrix,
                                       block_probs[:, j])
                energy += -omega_ij * pairwise / self.temperature
        
        # Normalize by molecular mass (approx: num_blocks)
        energy = energy / N
        
        return energy.mean()
    
    def reverse_step_with_guidance(self, z_t, t, z_P, noise_pred_net, 
                                   block_decoder, guidance_weight=1.0):
        """
        Reverse diffusion step with energy guidance
        """
        # Standard noise prediction
        eps_pred = noise_pred_net(z_t, t, z_P)  # Îµ_Î¸(z_t, t, z_P)
        
        # Denoised estimate: z_0 = (z_t - âˆš(1-Î±_t)Â·Îµ) / âˆšÎ±_t
        alpha_t = self.get_alpha(t)
        z_0_hat = (z_t - torch.sqrt(1 - alpha_t) * eps_pred) / torch.sqrt(alpha_t)
        
        # Compute energy and backprop gradient to noise space
        z_0_hat.requires_grad_(True)
        energy = self.compute_energy(z_0_hat, block_decoder)
        
        # âˆ‚E/âˆ‚z_0
        grad_z0 = torch.autograd.grad(energy, z_0_hat)[0]
        
        # Chain rule: âˆ‚E/âˆ‚Îµ = (âˆ‚E/âˆ‚z_0) * (âˆ‚z_0/âˆ‚Îµ)
        # From z_0 = (z_t - âˆš(1-Î±_t)Â·Îµ) / âˆšÎ±_t
        # â†’ âˆ‚z_0/âˆ‚Îµ = -âˆš(1-Î±_t) / âˆšÎ±_t
        grad_eps = -grad_z0 * torch.sqrt(1 - alpha_t) / torch.sqrt(alpha_t)
        
        # Gradient clipping for stability
        grad_norm = torch.norm(grad_eps)
        if grad_norm > 10.0:  # G_set = 10
            grad_eps = grad_eps * (10.0 / grad_norm)
        
        # Guided noise prediction
        # Îµ_guided = Îµ_Î¸ - Ï‰_t Â· âˆ‡_Îµ E
        eps_guided = eps_pred - guidance_weight * grad_eps
        
        # Standard DDPM reverse step
        z_prev = self.ddpm_reverse(z_t, t, eps_guided)
        
        return z_prev
```

Guidance weight $\omega_t$ëŠ” time stepì´ ì§„í–‰ë ìˆ˜ë¡ decayí•œë‹¤. ì´ˆê¸°ì—ëŠ” ê°•í•œ guidanceë¡œ coarse structureë¥¼ ì¡ê³ , í›„ë°˜ì—ëŠ” ì•½í•œ guidanceë¡œ fine detailì„ ì¡°ì •í•œë‹¤.

Training dataì—ì„œ ìì£¼ ë“±ì¥í•˜ëŠ” fragmentëŠ” general binding potentialì„ ë°˜ì˜í•˜ì§€ë§Œ, pocket specificityë¥¼ ë³´ì¥í•˜ì§€ ì•ŠëŠ”ë‹¤. ë°˜ë©´ frequency matrix $F$ë¥¼ statistical potentialë¡œ ì‚¬ìš©í•˜ë©´, **í˜„ì¬ query pocketê³¼ ìœ ì‚¬í•œ í™˜ê²½ì—ì„œ ì—­ì‚¬ì ìœ¼ë¡œ co-occurredí•œ fragment combination**ì„ ìš°ì„ ì‹œí•œë‹¤. ì¦‰, "ì´ pocket typeì—ì„œëŠ” fragment Aì™€ Bê°€ ìì£¼ í•¨ê»˜ ë“±ì¥í–ˆë‹¤"ëŠ” evolutionary signalì„ í™œìš©í•˜ì—¬, promiscuity-prone motif ìƒì„±ì„ ì–µì œí•˜ê³  pocket-specific binding patternì„ ê°•í™”í•œë‹¤.

### Training Procedure

Trainingì€ ë‘ ë‹¨ê³„ë¡œ ë‚˜ë‰œë‹¤: (1) Hierarchical VAE í•™ìŠµ, (2) Latent diffusion í•™ìŠµ.

**Stage 1: Hierarchical VAE**

Composite lossëŠ” atom-scale, block-scale, global contrastive termì˜ weighted sumì´ë‹¤. Atom-scale lossëŠ” focal loss for inter-block bond classification, cross-entropy for bond type prediction, MSE loss on predicted velocity fields, paired-distance loss for adjacent atom pairsë¥¼ í¬í•¨í•œë‹¤. Block-scale lossëŠ” KL divergence on attribute/coordinate latents, cross-entropy for block type classification, MSE for coarse centroid regressionì„ ì‚¬ìš©í•œë‹¤. Global contrastive lossëŠ” triplet-basedë¡œ ligandì™€ pocketì˜ global descriptorë¥¼ aligní•œë‹¤.

Training ì¤‘ì—ëŠ” teacher forcingì„ ì‚¬ìš©í•œë‹¤: atomic type, intra-block bond, 50%ì˜ inter-block bondë¥¼ ëª¨ë¸ì— ë…¸ì¶œí•œë‹¤. ì¶”ê°€ë¡œ 5%ì˜ pocket residueë¥¼ maskingí•œë‹¤.

**Stage 2: Latent Diffusion**

Latent diffusionì€ denoising MSE lossì™€ latent perceptual loss (LPL)ì˜ weighted sumìœ¼ë¡œ í•™ìŠµëœë‹¤:

$$\mathcal{L}_{\text{diffusion}} = \mathbb{E}_{t,\epsilon}\left[\|\epsilon - \epsilon_\theta(z_t, t, z_P)\|^2\right] + \lambda \cdot \text{LPL}(z_0, \hat{z}_0)$$

![Figure 2: Performance comparison](https://www.biorxiv.org/content/biorxiv/early/2025/11/08/2025.11.06.687093/F2.large.jpg)
_Figure 2: Small-molecule generative ëª¨ë¸ì˜ 5ê°œ ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¹„êµ. SpecLigê°€ Specificity, Interaction, Chemistryì—ì„œ ìµœê³  ì„±ëŠ¥. ì¶œì²˜: ì› ë…¼ë¬¸_

### Inference: Guided Sampling

Inference ì‹œì—ëŠ” Gaussian noise $z_T \sim \mathcal{N}(0, I)$ì—ì„œ ì‹œì‘í•˜ì—¬, energy-guided reverse stepì„ ë°˜ë³µì ìœ¼ë¡œ ìˆ˜í–‰í•œë‹¤. Guidance weightëŠ” ì´ˆê¸°ì—ëŠ” í¬ê²Œ ì„¤ì •í•˜ì—¬ global structureë¥¼ ì¡ê³ , ì ì°¨ ê°ì†Œì‹œì¼œ local refinementë¥¼ ìˆ˜í–‰í•œë‹¤.

## Results

### Small Molecule Design

SpecLigë¥¼ CrossDocked2020 benchmarkì—ì„œ í‰ê°€í–ˆë‹¤. Baselineìœ¼ë¡œëŠ” autoregressive (AR, Pocket2Mol, ResGen), diffusion-based (TargetDiff, DecompDiff), fragment-based (FLAG, D3FG, DrugGPS), voxel-based (LiGAN, VoxBind), continuous-space (MolCRAFT, UniMoMo) ë“± ë‹¤ì–‘í•œ íŒ¨ëŸ¬ë‹¤ì„ì˜ ëª¨ë¸ë“¤ê³¼ ë¹„êµí–ˆë‹¤.

| Category | SpecLig Rank | Key Metric | Comparison |
|---|---|---|---|
| **Specificity** | ğŸ¥‡ 1st | Î”E_pair = -0.83 | Ratio_pair = 58.73% |
| **Interaction** | ğŸ¥‡ 1st | MPBG = 15.17 | +53.4% vs VoxBind (9.90) |
| **Chemistry** | ğŸ¥‡ 1st | High QED, SA | Drug-like + specific |
| **Substructure** | ğŸ¥ˆ 2nd | Natural fragments | Best on fragment classes |
| **Geometry** | 3rd | Low collision | Bond-length improvable |

**Specificity ê²°ê³¼**: SpecLigëŠ” ëª¨ë“  specificity metricì—ì„œ 1ìœ„ ë˜ëŠ” 2ìœ„ë¥¼ ì°¨ì§€í–ˆë‹¤. Î”E_pair = -0.83ì€ targetì´ non-targetë³´ë‹¤ í‰ê·  0.83 kcal/mol ë” ê°•í•˜ê²Œ ê²°í•©í•¨ì„ ì˜ë¯¸í•œë‹¤. Ratio_pair = 58.73%ëŠ” ìƒì„±ëœ ë¶„ìì˜ 58.73%ê°€ targetì—ì„œ ë” ì¢‹ì€ docking scoreë¥¼ ê¸°ë¡í–ˆë‹¤ëŠ” ëœ»ì´ë‹¤.

**Interaction ê²°ê³¼**: MPBG = 15.17ë¡œ 2ìœ„ VoxBind (9.90) ëŒ€ë¹„ 53.4% í–¥ìƒ. ì´ëŠ” pocket-specific binding enhancementê°€ ëšœë ·í•¨ì„ ë³´ì—¬ì¤€ë‹¤.

**Chemistry ê²°ê³¼**: Drug-likeness (QED)ì™€ synthetic accessibility (SA)ì—ì„œ ìµœê³  ìˆ˜ì¤€ì„ ìœ ì§€í•˜ë©´ì„œ specificityë¥¼ ë‹¬ì„±í–ˆë‹¤.

**í•œê³„**: Small moleculeì—ì„œì˜ specificity ê°œì„ í­ì€ peptideë³´ë‹¤ ì‘ì•˜ë‹¤. ì €ìë“¤ì€ ì´ë¥¼ small moleculeì˜ discreteí•˜ê³  high-dimensionalí•œ chemical space ë•Œë¬¸ìœ¼ë¡œ ë¶„ì„í–ˆë‹¤. Functional group, aromatic system, rotatable bondì˜ combinatorial variationì´ highly multimodal energy landscapeë¥¼ í˜•ì„±í•˜ì—¬, ë‹¨ì¼ block vocabularyì˜ coverageê°€ ì œí•œì ì´ë‹¤.

### Peptide Design

PepBench, ProtFrag, LNR benchmarkì—ì„œ í‰ê°€í–ˆë‹¤. Baselineì€ RFDiffusion, PepFlow, PepGLAD, UniMoMoì´ë‹¤.

| Category | SpecLig Rank | Key Metric | Comparison |
|---|---|---|---|
| **Specificity** | ğŸ¥‡ 1st | Ratio_pair = 75.43% | Ratio_20 = 75.00% |
| **Interaction** | ğŸ¥‡ 1st | Î”G = -1.92 | Only negative mean |
| **Structural Validity** | ğŸ¥‡ 1st | Lowest Clash_out | Lowest L-RMSD |
| **Recovery** | ğŸ¥ˆ 2nd | Competitive AAR | Competitive C-RMSD |
| **Diversity** | 3rd | Slight reduction | Due to energy constraint |

![Figure 3: Peptide comparison](https://www.biorxiv.org/content/biorxiv/early/2025/11/08/2025.11.06.687093/F3.large.jpg)
_Figure 3: Peptide design ëª¨ë¸ì˜ 5ê°œ ì¹´í…Œê³ ë¦¬ë³„ ì„±ëŠ¥ ë¹„êµ. SpecLigê°€ Specificity, Interaction, Structural Validityì—ì„œ ìµœê³  ì„±ëŠ¥. ì¶œì²˜: ì› ë…¼ë¬¸_

**Specificity ê²°ê³¼**: Ratio_pairì™€ Ratio_20ì„ 2ìœ„ ëª¨ë¸ ëŒ€ë¹„ ê°ê° 6.68%p, 22.09%p í–¥ìƒì‹œì¼°ë‹¤. Native ligandì˜ ì„±ëŠ¥ (80.72%, 78.31%)ì— ê·¼ì ‘í–ˆë‹¤.

**Interaction ê²°ê³¼**: SpecLigë§Œ ìœ ì¼í•˜ê²Œ negative mean Î”G = -1.92ë¥¼ ë‹¬ì„±í–ˆë‹¤ (2ìœ„ UniMoMoëŠ” +29.21). ì´ëŠ” ëŒ€ë¶€ë¶„ì˜ ìƒì„± peptideê°€ favorable binding energyë¥¼ ë³´ì˜€ìŒì„ ì˜ë¯¸í•œë‹¤.

**Structural Validity**: Clash_outê³¼ L-RMSDì—ì„œ ìµœê³  ì„±ëŠ¥ìœ¼ë¡œ geometrically self-consistentí•œ outputì„ ìƒì„±í–ˆë‹¤.

### Case Study

ë…¼ë¬¸ì€ ë‘ ê°€ì§€ case studyë¥¼ ì œì‹œí•œë‹¤. Small moleculeì˜ ê²½ìš°, native ligand (cytochrome P450BM-3 ëŒ€ìƒ)ê°€ non-target (aldehyde decarbonylase)ì— ë” ê°•í•˜ê²Œ binding (Vina = -7.32 vs -6.08)í–ˆì§€ë§Œ, SpecLigê°€ ìƒì„±í•œ moleculeì€ targetì—ì„œ -9.58ì„ ê¸°ë¡í•˜ë©´ì„œ non-targetì—ì„œëŠ” valid docking poseì¡°ì°¨ ì°¾ì§€ ëª»í–ˆë‹¤.

Peptideì˜ ê²½ìš°, native peptide (microcin J25, ferrichrome-iron receptor ëŒ€ìƒ)ê°€ off-target rhodopsinì—ì„œ Î”G = -30.46ìœ¼ë¡œ target (-8.71)ë³´ë‹¤ í›¨ì”¬ ê°•í•˜ê²Œ ê²°í•©í–ˆì§€ë§Œ, SpecLig ë””ìì¸ì€ targetì—ì„œ Î”G = -60.21ì„ ê¸°ë¡í•˜ë©´ì„œ off-targetì—ì„œëŠ” feasible poseë¥¼ í˜•ì„±í•˜ì§€ ëª»í–ˆë‹¤.

![Figure 4: Case studies](https://www.biorxiv.org/content/biorxiv/early/2025/11/08/2025.11.06.687093/F4.large.jpg)
_Figure 4: SpecLigì˜ off-target binding ê°ì†Œ ì‚¬ë¡€. (a-d) Small molecule targeting cytochrome P450BM-3. (e-h) Peptide targeting ferrichrome-iron receptor. SpecLig ë””ìì¸ì€ targetì—ëŠ” ê°•í•˜ê²Œ ê²°í•©í•˜ì§€ë§Œ non-targetì—ì„œëŠ” valid poseë¥¼ í˜•ì„±í•˜ì§€ ëª»í•¨. ì¶œì²˜: ì› ë…¼ë¬¸_

## Discussion

SpecLigëŠ” hierarchical equivariant modelingê³¼ block-wise chemical prior í†µí•©ì„ í†µí•´ affinityì™€ specificityì˜ ê· í˜•ì„ ë‹¬ì„±í–ˆë‹¤. ë…¼ë¬¸ì—ì„œ ë°íŒ ì£¼ìš” insights:

**Mechanism**: Hierarchical VAEëŠ” atom-level noiseë¥¼ filteringí•˜ë©´ì„œ fragment semanticì„ ë³´ì¡´í•˜ê³ , energy-guided latent samplingì€ pocket-conditioned chemically plausible solutionì„ ìƒì„±í•œë‹¤. Ablation studyì—ì„œ ë‘ componentì˜ ìƒí˜¸ë³´ì™„ì  ì—­í• ì´ í™•ì¸ë˜ì—ˆë‹¤.

**Small Moleculeì˜ í•œê³„**: Discrete chemical complexityì™€ geometric sensitivityë¡œ ì¸í•´ peptideë³´ë‹¤ ê°œì„ í­ì´ ì‘ì•˜ë‹¤. ì €ìë“¤ì€ í–¥í›„ ì—°êµ¬ ë°©í–¥ìœ¼ë¡œ richer physical cue (force-field term, electrostatic field, conformational ensemble)ì˜ í†µí•©ì„ ì œì‹œí–ˆë‹¤.

**Adaptive Sizing**: SpecLigëŠ” ë‹¨ìˆœíˆ fragmentë¥¼ agglomerateí•˜ì§€ ì•ŠëŠ”ë‹¤. Supplementary analysisì—ì„œ ligand sizeê°€ blockì˜ initial settingë³´ë‹¤ **pocket topology**ì— ì˜í•´ ì£¼ë¡œ ê²°ì •ë¨ì„ í™•ì¸í–ˆë‹¤. ì´ëŠ” ëª¨ë¸ì´ pocket shapeì— adaptiveí•˜ê²Œ ë°˜ì‘í•¨ì„ ì˜ë¯¸í•œë‹¤.

**Experimental Validation í•„ìš”**: ë…¼ë¬¸ì€ computational benchmarkì— ì§‘ì¤‘í–ˆìœ¼ë©°, prospective experimental validationì´ ì•„ì§ í•„ìš”í•˜ë‹¤. ì €ìë“¤ì€ ì´ë¥¼ future workìœ¼ë¡œ ì–¸ê¸‰í–ˆë‹¤.

**Generalizability**: SpecLigëŠ” small moleculeê³¼ peptideë¥¼ unified frameworkì—ì„œ ì²˜ë¦¬í•œë‹¤. ë™ì¼í•œ physicochemical rule (bond type, angle, steric clash)ì„ ê³µìœ í•˜ë¯€ë¡œ, ë‹¤ë¥¸ ligand modality (e.g., RNA aptamer, PROTACs)ë¡œ í™•ì¥ ê°€ëŠ¥ì„±ì´ ìˆë‹¤.

ì €ìë“¤ì´ ì œì‹œí•œ **í–¥í›„ ì—°êµ¬ ë°©í–¥**:
- Force-field energy, electrostatic potential ë“± physics-based termê³¼ì˜ hybrid guidance
- Conformational ensemble samplingì„ í†µí•œ binding mode diversity í™•ë³´
- Experimental validationì„ í†µí•œ in silico-in vitro correlation ê²€ì¦
- ë‹¤ë¥¸ ligand modalityë¡œì˜ í™•ì¥

## TL;DR

- **Problem**: ê¸°ì¡´ SBDD ëª¨ë¸ì€ affinityëŠ” ë†’ì´ì§€ë§Œ off-target bindingì„ ìœ ë°œí•˜ëŠ” promiscuous binderë¥¼ ìƒì„±
- **Solution**: Hierarchical SE(3)-equivariant VAE + energy-guided latent diffusion. Block-block contact frequencyë¥¼ statistical energyë¡œ ë³€í™˜í•˜ì—¬ diffusion sampling guide
- **Results**: Small moleculeê³¼ peptide ëª¨ë‘ì—ì„œ ë†’ì€ specificityì™€ affinity ë‹¬ì„±. PeptideëŠ” Ratio_pair 75.43%, Î”G -1.92; Small moleculeì€ MPBG 15.17ë¡œ baseline ëŒ€ë¹„ 53.4% í–¥ìƒ

## Paper Info

| í•­ëª© | ë‚´ìš© |
|---|---|
| **Title** | SpecLig: Energy-Guided Hierarchical Model for Target-Specific 3D Ligand Design |
| **Authors** | Chunqiu Zhang et al. (Tsinghua University, Beijing National Research Center for Information Science and Technology) |
| **Venue** | bioRxiv preprint |
| **Submitted** | 2025-11-06 |
| **Paper** | [bioRxiv](https://www.biorxiv.org/content/10.1101/2025.11.06.687093v1) |
| **Code** | [GitHub](https://github.com/CQ-zhang-2016/SpecLig) |

---

> ì´ ê¸€ì€ LLM(Large Language Model)ì˜ ë„ì›€ì„ ë°›ì•„ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤. 
> ë…¼ë¬¸ì˜ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë‚˜, ë¶€ì •í™•í•œ ë‚´ìš©ì´ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
> ì˜¤ë¥˜ ì§€ì ì´ë‚˜ í”¼ë“œë°±ì€ ì–¸ì œë“  í™˜ì˜í•©ë‹ˆë‹¤.
{: .prompt-info }
