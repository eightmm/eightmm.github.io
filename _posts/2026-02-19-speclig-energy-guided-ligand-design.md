---
title: "SpecLig: Energy-Guided Hierarchical Model for Target-Specific 3D Ligand Design"
date: 2026-02-19 15:00:00 +0900
categories: [AI, Drug Discovery]
tags: [protein-ligand, drug-design, diffusion, equivariant, specificity, VAE, structure-based, peptide-design]
math: true
image:
  path: https://www.biorxiv.org/content/biorxiv/early/2025/11/08/2025.11.06.687093/F1.large.jpg
  alt: "SpecLig framework overview"
---

> **Hierarchical SE(3)-equivariant VAE + energy-guided latent diffusionìœ¼ë¡œ ì¹œí™”ë„ì™€ íŠ¹ì´ì„±ì„ ë™ì‹œì— ë‹¬ì„±í•˜ëŠ” í†µí•© ë¦¬ê°„ë“œ ìƒì„± í”„ë ˆì„ì›Œí¬**
{: .prompt-tip }

| í•­ëª© | ë‚´ìš© |
|---|---|
| **ì•½ì–´** | SpecLig |
| **ì¤‘ìš”ë„** | â­â­â­â­â­ |
| **Track** | ğŸ§¬ Protein-Ligand |
| **Paper** | [bioRxiv 2025.11.06.687093](https://www.biorxiv.org/content/10.1101/2025.11.06.687093v1) |
| **Code** | [GitHub: CQ-zhang-2016/SpecLig](https://github.com/CQ-zhang-2016/SpecLig) |
| **Funding** | NSFC T2541010, National Key R&D 2024YFF1207103, BNRist |

---

## ğŸ¯ í•µì‹¬ ê¸°ì—¬ (Key Contributions)

1. **Specificity-aware SBDD**: ê¸°ì¡´ SBDD ëª¨ë¸ì´ ë¬´ì‹œí•˜ë˜ **target specificity**ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ëª¨ë¸ë§í•œ ìµœì´ˆì˜ í†µí•© í”„ë ˆì„ì›Œí¬. ë‹¨ì¼ íƒ€ê²Ÿ affinityë§Œ ìµœì í™”í•˜ë©´ off-target bindingì´ ì¦ê°€í•œë‹¤ëŠ” ë¬¸ì œë¥¼ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ê³  í•´ê²°
2. **Block-based hierarchical representation**: ë¶„ìë¥¼ atom ìˆ˜ì¤€ì´ ì•„ë‹Œ **fragment(block) ë‹¨ìœ„**ë¡œ í‘œí˜„í•˜ê³ , atom-scale â†’ block-scaleì˜ ê³„ì¸µì  SE(3)-equivariant VAEë¡œ multi-scale ì •ë³´ë¥¼ í¬ì°©
3. **Energy-guided latent diffusion**: ìì—° ë³µí•©ì²´ì—ì„œ ì¶”ì¶œí•œ block-block ì ‘ì´‰ ë¹ˆë„ í†µê³„ë¥¼ ì—ë„ˆì§€ í•¨ìˆ˜ë¡œ ë³€í™˜í•˜ì—¬ diffusion sampling ê³¼ì •ì—ì„œ **pocket-complementary fragment ì¡°í•©**ì„ ìœ ë„
4. **Unified small molecule + peptide design**: í•˜ë‚˜ì˜ í”„ë ˆì„ì›Œí¬ë¡œ ì†Œë¶„ìì™€ í©íƒ€ì´ë“œë¥¼ ëª¨ë‘ ìƒì„±. Specificityë¥¼ ì •ëŸ‰í™”í•˜ëŠ” **precision/breadth í…ŒìŠ¤íŠ¸ íŒ¨ëŸ¬ë‹¤ì„** ì œì•ˆ

---

## ğŸ“Š ì£¼ìš” ê²°ê³¼ (Key Results)

### Small Molecule Design (CrossDocked2020)

| Model | Specificity Rank | Interaction Rank | Chemistry Rank | Overall Score |
|---|---|---|---|---|
| **SpecLig** | **1st** | **1st** | **1st** | **0.829** |
| VoxBind | 2nd | 3rd | 6th | 0.686 |
| UniMoMo | 6th | 2nd | 4th | 0.614 |
| DecompDiff | 3rd | 5th | 5th | 0.571 |
| MolCRAFT | 5th | 4th | 3rd | 0.571 |

**í•µì‹¬ ìˆ˜ì¹˜:**
- $\Delta E_{\text{pair}} = -0.83$ (target vs non-target docking score ì°¨ì´)
- $\text{Ratio}_{\text{pair}} = 58.73\%$ (targetì— ë” ê°•í•˜ê²Œ ê²°í•©í•˜ëŠ” ë¹„ìœ¨)
- $\text{MPBG} = 15.17$ (VoxBind ëŒ€ë¹„ **53.4% ìƒëŒ€ ê°œì„ **)

### Peptide Design (PepBench, ProtFrag, LNR)

| Model | Specificity Rank | Interaction Rank | Recovery Rank | Overall Score |
|---|---|---|---|---|
| **SpecLig** | **1st** | **1st** | **1st** | **0.850** |
| UniMoMo | 2nd | 2nd | 2nd | 0.700 |
| PepGLAD | 3rd | 3rd | 4th | 0.500 |
| PepFlow | 4th | 5th | 3rd | 0.350 |
| RFDiffusion | 5th | 4th | 5th | 0.200 |

**í•µì‹¬ ìˆ˜ì¹˜:**
- $\text{Ratio}_{\text{pair}}$: ê¸°ì¡´ best 68.75% â†’ **75.43%** (native ligand: 80.72%)
- $\text{Ratio}_{20}$: ê¸°ì¡´ best 52.91% â†’ **75.00%** (native ligand: 78.31%)
- ìœ ì¼í•˜ê²Œ **ìŒìˆ˜ Î”G** ë‹¬ì„±: $\Delta G = -1.92$ (2ìœ„ UniMoMo: 29.21)

---

## ğŸ§­ ë°°ê²½ (Background)

### ë¬¸ì œ ì •ì˜

Structure-based drug design (SBDD)ì€ ìˆ˜ìš©ì²´ì˜ 3D êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬ ë¦¬ê°„ë“œë¥¼ ìƒì„±í•˜ëŠ” ì ‘ê·¼ë²•ì´ë‹¤. ê¸°ì¡´ SBDD ëª¨ë¸ë“¤ì€ **ë‹¨ì¼ íƒ€ê²Ÿì— ëŒ€í•œ docking score ìµœì í™”**ì— ì§‘ì¤‘í•˜ì§€ë§Œ, ì´ëŠ” ì‹¬ê°í•œ ë¬¸ì œë¥¼ ì•¼ê¸°í•œë‹¤:

> ë†’ì€ predicted affinityë¥¼ ê°€ì§„ ìƒì„± ë¶„ìê°€ **ì˜ë„í•˜ì§€ ì•Šì€ ë‹¨ë°±ì§ˆì—ë„ ê°•í•˜ê²Œ ê²°í•©** (off-target binding)
{: .prompt-warning }

### ê¸°ì¡´ í•œê³„

ë…¼ë¬¸ì€ VoxBind, PepGLAD ë“± ê¸°ì¡´ ëª¨ë¸ì˜ ìƒì„±ë¬¼ì„ ë¶„ì„í•˜ì—¬ ì²´ê³„ì ì¸ ë¬¸ì œë¥¼ ë°œê²¬í–ˆë‹¤:

1. **Promiscuous binder ìƒì„±**: íƒ€ê²Ÿ affinityëŠ” ë†’ì§€ë§Œ off-targetì—ë„ ê°•í•˜ê²Œ ê²°í•©
2. **Small moleculeì—ì„œ**: ë‚®ì€ specificity ë¶„ìëŠ” **polar group ë¹„ìœ¨ì´ 5-10% ë†’ìŒ** â†’ ì—¬ëŸ¬ íƒ€ê²Ÿì— ë¹„íŠ¹ì´ì  ê²°í•©
3. **Peptideì—ì„œ**: ë†’ì€ specificity í©íƒ€ì´ë“œëŠ” **helical êµ¬ì¡° ë¹„ìœ¨ì´ 3-10% ë†’ìŒ** â†’ ë¹„í—¬ë¦­ìŠ¤ ìœ ì—° ì„¸ê·¸ë¨¼íŠ¸ê°€ off-target ë…¸ì¶œ ì¦ê°€
4. **ê¸°ì¡´ specificity ì¸¡ì •**: ë‹¨ì¼ ëœë¤ non-targetê³¼ ë¹„êµí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë¶ˆì¶©ë¶„

### í•µì‹¬ ì¸ì‚¬ì´íŠ¸

> Target specificityë¥¼ ë‹¬ì„±í•˜ë ¤ë©´ ë‹¨ì¼ êµ¬ì¡° conditioningì„ ë„˜ì–´ **ì§„í™”ì  binding preference**ë¥¼ ë°˜ì˜í•´ì•¼ í•œë‹¤. ìì—° ë³µí•©ì²´ì˜ fragment-fragment ì ‘ì´‰ ë¹ˆë„ í†µê³„ê°€ ì´ ì •ë³´ë¥¼ ë‹´ê³  ìˆë‹¤.
{: .prompt-info }

---

## ğŸ”¬ ë°©ë²•ë¡  (Methodology)

### Step 1: Block-based Graph Representation

ë‹¨ë°±ì§ˆ-ë¦¬ê°„ë“œ ë³µí•©ì²´ë¥¼ **block-based graph** $G = (V, E)$ë¡œ í‘œí˜„í•œë‹¤:
- ê° ë…¸ë“œ $v_i \in V$ëŠ” block(fragment) ë‹¨ìœ„ â€” amino acid residue ë˜ëŠ” small-molecule fragment
- ê° block: $v_i = \{(a_k, x_k)\}_{k=1}^{n_i}$ (ì›ì†Œ íƒ€ì… + 3D ì¢Œí‘œ)
- Block vocabulary $S$: canonical amino acids + predefined small-molecule fragments
- **Controllable flag** $p_i \in \{0, 1\}$: $p_i = 1$ì´ë©´ canonical residueë¡œë§Œ sampling

### Step 2: Hierarchical SE(3)-Equivariant VAE

2ë‹¨ê³„ ê³„ì¸µì  ì¸ì½”ë”©-ë””ì½”ë”©:

$$p(G_L | G_P) = \int p_\phi(G_L | Z_L^0, Z_P) \cdot p_\theta(Z_L^0 | Z_P) \, dZ_L^0$$

1. **Atom-scale encoder** $\mathcal{E}_{\xi,1}$: atom-level features (ì›ì†Œ íƒ€ì…, ë¶€ëª¨ block íƒ€ì…, residue flag, chain id) + empirical frequency matrix $F$ì—ì„œ í•™ìŠµí•œ correlated projection
2. **Block-scale encoder** $\mathcal{E}_{\xi,2}$: atom-level output ìœ„ì— coarser KNN graph êµ¬ì„±

### Step 3: Statistical Prior Construction

ìì—° ë³µí•©ì²´ë¡œë¶€í„° block-block ì ‘ì´‰ ë¹ˆë„ í–‰ë ¬ $F \in \mathbb{R}^{n_s \times n_s}$ êµ¬ì¶•:

| Source | Data |
|---|---|
| ZINC15 + ChEMBL | Fragment-fragment ê³µì¶œí˜„ ë¹ˆë„ (100ë§Œ+ small molecules) |
| RCSB PDB + PepBDB | Inter-chain hydrogen bond residue pairs |
| PDBbind + Binding-MOAD | Protein-ligand interaction ë¹ˆë„ (BINANA ë¶„ì„) |

â†’ Sourceë³„ ì •ê·œí™” í›„ log-transform â†’ ì—°ì† statistical potential

### Step 4: Energy-Guided Latent Diffusion

Reverse diffusion stepë§ˆë‹¤ ì—ë„ˆì§€ í•­ìœ¼ë¡œ ê°€ì´ë“œ:

$$E_{ij} = -\hat{s}_i^\top \left(\frac{F}{\tau}\right) \hat{s}_j \cdot \omega_{ij}$$

ì—¬ê¸°ì„œ:
- $\hat{s}_i$: ë””ì½”ë”ê°€ ì˜ˆì¸¡í•œ block-type probability vector
- $\tau$: temperature smoothing factor
- $\omega_{ij}$: distance-dependent decay

ì—ë„ˆì§€ gradientë¥¼ noise spaceë¡œ backpropagationí•˜ì—¬ sampling ì¡°ì •:

$$\hat{\epsilon}_t' = \hat{\epsilon}_t - \omega_t \cdot \text{clip}(\nabla_{\epsilon} E, G_{\text{set}})$$

---

## ğŸ—ï¸ ëª¨ë¸ ì•„í‚¤í…ì²˜ (Architecture Detail)

### ì „ì²´ íŒŒì´í”„ë¼ì¸

```mermaid
graph TD
    A[Protein-Ligand Complex] --> B[Block-based Graph G = V, E]
    B --> C[Atom-scale Encoder â„°Î¾,1]
    C --> D[Block-scale Encoder â„°Î¾,2]
    D --> E[Latent Space Z]
    E --> F[Energy-Guided Latent Diffusion]
    F --> G[Block-scale Decoder ğ’ŸÏ•,2]
    G --> H[Atom-scale Decoder ğ’ŸÏ•,1]
    H --> I[Generated Ligand: types + 3D coords]
    
    J[Statistical Prior F] --> F
    K[Block-Block Frequency Matrix] --> J
```

### Module A: Atom-scale Encoder ($\mathcal{E}_{\xi,1}$)

| Parameter | Value |
|---|---|
| **Input features** | Element type, parent block type, canonical-residue flag, chain id |
| **Graph construction** | KNN graph (intra-$G_L$ and intra-$G_P$ separately, no cross-information) |
| **Edge features** | Same-block indicator $e_{ab}$, relative distance $d_{ab}$, candidate bond type $\beta_{ab}$ |
| **Architecture** | SE(3)-equivariant transformer |
| **Augmentation** | Correlated projection from frequency matrix $F$ (temperature-scaled normalization) |

> **í•µì‹¬**: KNN graph êµ¬ì„± ì‹œ $G_L$ê³¼ $G_P$ ì‚¬ì´ ì •ë³´ êµí™˜ì„ **ì°¨ë‹¨**í•˜ì—¬ information leakage ë°©ì§€
{: .prompt-info }

### Module B: Block-scale Encoder ($\mathcal{E}_{\xi,2}$)

| Parameter | Value |
|---|---|
| **Input** | Atom-scale encoder output (pooled per block) |
| **Graph construction** | Coarser KNN graph on block centroids |
| **Edge features** | Relative distances between block centroids |
| **Output** | Distributional parameters $(\mu_\xi, \sigma_\xi)$ for reparameterized sampling |
| **Latent dimension** $d$ | 8 |
| **Architecture** | SE(3)-equivariant transformer |

Latent representation: $Z_i = [z_i^h, z_i^x] \in \mathbb{R}^d$ (attribute latent $z^h$ + coordinate latent $z^x$)

### Module C: Energy-Guided Geometric Diffusion

| Parameter | Value |
|---|---|
| **Diffusion space** | Latent space (not atom space) |
| **Energy function** | Block-block frequency matrix-based statistical potential |
| **Temperature** $\tau$ | Smoothing factor for probability |
| **Gradient clipping** | Norm-based, bound $G_{\text{set}}$ |
| **Guidance weight** $\omega_t$ | Time-step dependent decay |
| **Noise injection** | Gaussian noise to model deviations during diffusion (robustness) |

### Module D: Hierarchical Decoder ($\mathcal{D}_{\phi}$)

Block-scale decoder $\mathcal{D}_{\phi,2}$:
- Block type ë¶„ë¥˜ + coarse centroid regression
- ì—ë„ˆì§€ ê°€ì´ë“œ ì‹œ frozen ìƒíƒœë¡œ block-type probability vector ìƒì„±

Atom-scale decoder $\mathcal{D}_{\phi,1}$:
- Full-atom 3D coordinate ì¬êµ¬ì„±
- Iterative decoding with velocity field supervision

### Pocket ì •ì˜

> Pocket = native ligand atomìœ¼ë¡œë¶€í„° **10Ã… ì´ë‚´**ì— reference point ($C_\beta$ ë˜ëŠ” fragment centroid)ê°€ ìˆëŠ” blockë“¤
{: .prompt-info }

---

## ğŸ§© Pseudocode

### Training (VAE Stage)

```python
# Hierarchical VAE Training
for complex in dataset:
    G_P, G_L = build_block_graph(complex)
    
    # Atom-scale encoding (separate KNN for pocket and ligand)
    h_atom_P = atom_encoder(G_P, knn_graph='intra')
    h_atom_L = atom_encoder(G_L, knn_graph='intra')
    
    # Block-scale encoding
    mu, sigma = block_encoder(h_atom_P, h_atom_L)
    Z = reparameterize(mu, sigma)  # Z = [z_h, z_x], d=8
    
    # Decoding
    block_types, centroids = block_decoder(Z)
    atom_coords, bonds = atom_decoder(block_types, centroids)
    
    # Loss computation
    L_atom = focal_bond_loss + velocity_mse + paired_distance_loss
    L_block = KL_divergence + block_type_CE + centroid_regression
    L_global = triplet_contrastive_loss(ligand_desc, pocket_desc)
    
    loss = L_atom + L_block + L_global
    loss.backward()
```

### Sampling (Energy-Guided Diffusion)

```python
# Energy-Guided Latent Diffusion Sampling
Z_T ~ N(0, I)  # Start from noise

for t in reversed(range(T)):
    # Predict noise
    eps_pred = noise_network(Z_t, Z_P, t)
    
    # Denoise to get Z_0 estimate
    Z_0_hat = denoise(Z_t, eps_pred, t)
    
    # Decode block types (frozen decoder)
    s_hat = frozen_block_decoder(Z_0_hat)  # probability vectors
    
    # Compute energy from block-block prior
    E = 0
    for (i, j) in block_pairs:
        E_ij = -s_hat[i].T @ (F / tau) @ s_hat[j] * omega_dist(i, j)
        E += E_ij
    E = E / molecular_mass  # normalize
    
    # Energy gradient guidance
    grad = backprop(E, eps_pred)
    grad = clip_by_norm(grad, G_set)
    eps_guided = eps_pred - omega_t * grad
    
    # Reverse step with guided noise
    Z_{t-1} = reverse_step(Z_t, eps_guided, t)

# Final decoding
ligand = full_decoder(Z_0)
```

---

## ğŸ§ª ì‹¤í—˜ ì…‹ì—… (Experimental Setup)

### ë°ì´í„°ì…‹

| Dataset | Task | Split | Usage |
|---|---|---|---|
| **CrossDocked2020** | Small molecule design | Standard (by CBGBench) | Train + Test |
| **PepBench** | Peptide design | Author-recommended | Train + Test |
| **ProtFrag** | Peptide design | Author-recommended | Test |
| **LNR** | Peptide design | Author-recommended | Test |
| **ChEMBL** (100K) | Small molecule augmentation | 20% structural masking | Train augmentation |
| **ZINC15** | Fragment statistics | N/A | Prior construction |
| **PDBbind + Binding-MOAD** | Interaction statistics | N/A | Prior construction |
| **RCSB PDB + PepBDB** | H-bond statistics | N/A | Prior construction |

### Training Configuration

| Parameter | Detail |
|---|---|
| **Training strategy** | Sequential: VAE first â†’ Latent diffusion |
| **VAE teacher forcing** | Atomic types, intra-block bonds, 50% inter-block bonds exposed |
| **Pocket masking** | 5% of pocket residues masked during training |
| **Equivariant backbone** | SE(3)-equivariant transformer |
| **Latent dimension** | $d = 8$ |
| **Paired-distance loss** | Adjacent atoms (â‰¤6Ã…), early decoding steps ($t \leq 0.25$) only |
| **Diffusion loss** | Denoising MSE + Latent Perceptual Loss (LPL) |
| **Contrastive loss** | Triplet-based: ligand â†” cognate pocket (positive), random pocket (negative) |

### Specificity Evaluation Protocols

| Protocol | Tool | Target Set Size | Ligand Type |
|---|---|---|---|
| **Precision (Peptide)** | PyRosetta side-chain docking | 1 target + 1 non-target | Peptide |
| **Breadth (Peptide)** | PyRosetta | 100 proteins | Peptide |
| **Precision (Small mol)** | AutoDock Vina | 1 target + 1 non-target | Small molecule |
| **Breadth (Small mol)** | Uni-Dock (GPU-accelerated) | 2000 proteins | Small molecule |

---

## ğŸ”— ì—°êµ¬ ì—°ê²°ì  (Research Connection)

### Protein-Ligand AI ê´€ì 

- **Specificity as a first-class objective**: ê¸°ì¡´ SBDD ë²¤ì¹˜ë§ˆí¬ê°€ affinityë§Œ ì¸¡ì •í•˜ëŠ” í•œê³„ë¥¼ ì§€ì í•˜ê³ , specificity ë©”íŠ¸ë¦­ì„ ì²´ê³„ì ìœ¼ë¡œ ë„ì…. ì´ëŠ” í–¥í›„ PL ëª¨ë¸ í‰ê°€ì˜ ìƒˆë¡œìš´ ê¸°ì¤€ì´ ë  ìˆ˜ ìˆìŒ
- **Block-based representation**: Atom ìˆ˜ì¤€ì´ ì•„ë‹Œ fragment ìˆ˜ì¤€ì˜ í‘œí˜„ì€ chemical spaceì˜ ì˜ë¯¸ ìˆëŠ” ë‹¨ìœ„ë¥¼ ë³´ì¡´í•˜ë©´ì„œ ê³„ì‚° íš¨ìœ¨ì„±ì„ í™•ë³´

### Flow Matching ê´€ì 

- ë…¼ë¬¸ì€ diffusion ê¸°ë°˜ì´ì§€ë§Œ, **energy guidance ë©”ì»¤ë‹ˆì¦˜ì€ flow matchingì—ë„ ì§ì ‘ ì ìš© ê°€ëŠ¥**
- Conditional flow matchingì˜ velocity fieldì— energy gradientë¥¼ ì£¼ì…í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥
- Statistical prior (block-block frequency)ëŠ” model-agnosticí•œ guidance signal

### Drug Discovery ê´€ì 

> Off-target toxicityëŠ” drug development failureì˜ ì£¼ìš” ì›ì¸ ì¤‘ í•˜ë‚˜. SpecLigì˜ specificity-aware generationì€ **hit-to-lead ê³¼ì •ì—ì„œ safety profile ê°œì„ **ì— ì§ì ‘ì ìœ¼ë¡œ ê¸°ì—¬í•  ìˆ˜ ìˆë‹¤.
{: .prompt-tip }

- Precision/breadth í…ŒìŠ¤íŠ¸ íŒ¨ëŸ¬ë‹¤ì„ì€ ê¸°ì¡´ ë…¼ë¬¸ì˜ ë‹¤ì†Œ ì„ì˜ì ì¸ specificity í‰ê°€ë¥¼ ëŒ€ì²´í•˜ëŠ” ì²´ê³„ì  í”„ë¡œí† ì½œ
- ì†Œë¶„ìì™€ í©íƒ€ì´ë“œë¥¼ í•˜ë‚˜ì˜ í”„ë ˆì„ì›Œí¬ë¡œ ë‹¤ë£¨ë¯€ë¡œ, multi-modality drug design pipelineì— í†µí•© ê°€ëŠ¥

---

## ğŸ’­ Open Questions / í›„ì† ì‹¤í—˜ ì•„ì´ë””ì–´

1. **Flow matching adaptation**: Energy guidanceë¥¼ flow matching framework (e.g., FlowSite, PepFlow)ì— ì ìš©í•˜ë©´ ì–´ë–¤ ì„±ëŠ¥ ì°¨ì´ê°€ ë‚˜ëŠ”ê°€?
2. **Force field integration**: ë…¼ë¬¸ ìì²´ë„ ì¸ì •í•˜ë“¯, block-block frequencyë§Œìœ¼ë¡œëŠ” ì†Œë¶„ìì˜ ë³µì¡í•œ energy landscapeë¥¼ ì¶©ë¶„íˆ í¬ì°©í•˜ê¸° ì–´ë ¤ì›€. Explicit force-field terms, electrostatic fieldsë¥¼ ì¶”ê°€í•˜ë©´?
3. **Conformational ensemble**: ë‹¨ì¼ crystal structureê°€ ì•„ë‹Œ MD ensembleì„ conditioningí•˜ë©´ specificityê°€ ë” ê°œì„ ë˜ëŠ”ê°€?
4. **Scalability**: Block vocabulary í¬ê¸° $n_s$ê°€ ì»¤ì§€ë©´ frequency matrixì˜ sparsity ë¬¸ì œ â†’ learned embeddingìœ¼ë¡œ ëŒ€ì²´ ê°€ëŠ¥?
5. **Diversity-specificity trade-off**: ì—ë„ˆì§€ ê°€ì´ë“œê°€ ê°•í• ìˆ˜ë¡ mode collapse â†’ adaptive guidance schedulingì´ë‚˜ classifier-free guidanceì™€ì˜ ê²°í•©ì€?
6. **Experimental validation**: In silico ê²°ê³¼ë§Œ ìˆìŒ â†’ wet-lab validationì´ í•µì‹¬ í›„ì† ê³¼ì œ
7. **AF3/Boltz-2 integration**: SpecLigì˜ ìƒì„±ë¬¼ì„ AF3ë‚˜ Boltz-2ë¡œ re-dockingí•˜ì—¬ specificityë¥¼ ì¶”ê°€ ê²€ì¦í•˜ëŠ” íŒŒì´í”„ë¼ì¸

---

## ğŸ”§ ì¬í˜„ì„± í‰ê°€ (Reproducibility)

| í•­ëª© | í‰ê°€ |
|---|---|
| **ì½”ë“œ ê³µê°œ** | âœ… [GitHub](https://github.com/CQ-zhang-2016/SpecLig) |
| **í•™ìŠµ ë°ì´í„° ì ‘ê·¼ì„±** | âœ… ê³µê°œ (CrossDocked2020, PepBench, ChEMBL, ZINC15 ë“± ëª¨ë‘ public) |
| **Statistical prior data** | âœ… ê³µê°œ DB (PDB, PDBbind, Binding-MOAD, PepBDB) |
| **í•„ìš” GPU ë¦¬ì†ŒìŠ¤** | ë¯¸ëª…ì‹œ (Supplementaryì— ìˆì„ ìˆ˜ ìˆìŒ) |
| **ì¬í˜„ ë‚œì´ë„** | â­â­â­ (ì½”ë“œ+ë°ì´í„° ê³µê°œì´ë‚˜ 2-stage training + energy guidance íŠœë‹ í•„ìš”) |

> Statistical prior êµ¬ì¶• ìì²´ê°€ ìƒë‹¹í•œ ì „ì²˜ë¦¬ë¥¼ ìš”êµ¬ (BINANA ë¶„ì„, hydrogen bond trajectory ë¶„ì„ ë“±). ì½”ë“œì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ í•„ìš”.
{: .prompt-warning }

---

## ğŸ“ ë¦¬ì†ŒìŠ¤ (Resources)

- ğŸ“„ **Paper**: [bioRxiv 2025.11.06.687093](https://www.biorxiv.org/content/10.1101/2025.11.06.687093v1)
- ğŸ’» **Code**: [GitHub: CQ-zhang-2016/SpecLig](https://github.com/CQ-zhang-2016/SpecLig)
- ğŸ“Š **Benchmark**: [CBGBench](https://github.com/cbgbench) (small molecule), PepBench (peptide)
- ğŸ”§ **Docking tools used**: AutoDock Vina, Uni-Dock, PyRosetta, SchrÃ¶dinger Glide

### Baselines Referenced

| Model | Paradigm | Paper |
|---|---|---|
| Pocket2Mol | 3D Autoregressive | Peng et al., ICML 2022 |
| TargetDiff | Diffusion | Guan et al., 2023 |
| DecompDiff | Decomposed Diffusion | Guan et al., 2024 |
| FLAG | Fragment-based | Zhang et al., ICLR 2023 |
| D3FG | Functional-group Diffusion | Lin et al., NeurIPS 2023 |
| VoxBind | Voxel-based Denoising | Pinheiro et al., 2024 |
| MolCRAFT | Continuous-space | Qu et al., 2024 |
| UniMoMo | Unified Multimodal | Kong et al., 2025 |
| RFDiffusion | Diffusion (Protein) | Watson et al., Nature 2023 |
| PepFlow | Flow Matching (Peptide) | Lin et al., 2024 |
| PepGLAD | Latent Diffusion (Peptide) | Kong et al., NeurIPS 2024 |

---

## ğŸ“ ì£¼ìš” ìˆ˜ì‹ ì •ë¦¬

### Generation Probability (Marginalized Form)

$$p(G_L | G_P) = \int p_\phi(G_L | Z_L^0, Z_P) \cdot p_\theta(Z_L^0 | Z_P) \, dZ_L^0$$

### Pairwise Energy Term

$$E_{ij} = -\hat{s}_i^\top \left(\frac{F}{\tau}\right) \hat{s}_j \cdot \omega_{ij}$$

### Guided Noise Prediction

$$\hat{\epsilon}_t' = \hat{\epsilon}_t - \omega_t \cdot \text{clip}\left(\nabla_{\epsilon} E, \, G_{\text{set}}\right)$$

### Training Loss (VAE Stage)

$$\mathcal{L}_{\text{VAE}} = \underbrace{\mathcal{L}_{\text{focal}} + \mathcal{L}_{\text{bond-CE}} + \mathcal{L}_{\text{velocity-MSE}} + \mathcal{L}_{\text{paired-dist}}}_{\text{Atom-scale}} + \underbrace{\mathcal{L}_{\text{KL}} + \mathcal{L}_{\text{block-type}} + \mathcal{L}_{\text{centroid}}}_{\text{Block-scale}} + \mathcal{L}_{\text{contrastive}}$$

### Training Loss (Diffusion Stage)

$$\mathcal{L}_{\text{diffusion}} = \mathcal{L}_{\text{denoise-MSE}} + \lambda \cdot \mathcal{L}_{\text{LPL}}$$
